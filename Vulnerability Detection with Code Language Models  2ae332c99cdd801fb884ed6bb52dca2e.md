# Vulnerability Detection with Code Language Models: How Far Are We?

Authors: Yangruibo Ding; Yanjun Fu; Omniyyah Ibrahim; Chawin Sitawarin; Xinyun Chen; Basel Alomair; David Wagner; Baishakhi Ray; Yizheng Chen
Venue: ICSE 2025
Year: 2025
Topic / Keywords: Vulnerability Detection（漏洞检测）
Dataset Quality（数据集质量）Temporal Split（时间切分）Deduplication（去重）
Benchmark（基准评测）
Category: Benchmark
Link: https://arxiv.org/abs/2403.18624
Status: Reading
My Takeaway: 现有代码漏洞检测数据集质量低且存在数据泄露，使模型性能被严重高估；PrimeVul 通过更准确标注、严格去重与时间切分揭示出当前模型在真实场景中几乎失效，说明漏洞检测领域亟需更可靠基准与更强模型。

Abstract：

In the context of the rising interest in **code language models (代码大语言模型)**(code LMs) and **vulnerability detection(VD, 漏洞检测)**, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.

**Code LMs (Code Language Models, 代码大语言模型):** 专门在代码语料上训练的大模型，比如 GitHub Copilot 背后的 Codex，或者 CodeLlama。

**Vulnerability Detection (VD, 漏洞检测):** 指使用工具自动扫描代码，找出其中可能被黑客利用的Bug（如SQL注入、缓冲区溢出）。这是网络安全和软件工程的交叉领域

**Shortcomings (缺陷):** 作者指出了当前学术界的三大痛点：

- **Data Quality:** 很多代码片段是不完整的。
- **Label Accuracy (标签准确度):** 很多被标记为“有漏洞”的代码其实是没问题的（假阳性），反之亦然。
- **Duplication (数据泄露/重复):** 训练集和测试集里有一样的代码，就像考试前把答案背下来了，考试成绩虚高。

To address these challenges, we introduce **PrimeVul**, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to **human-verified benchmarks** while significantly expanding the dataset. It also implements a rigorous data de-duplication and **chronological data splitting** strategy to mitigate **data leakage** issues, alongside introducing more realistic evaluation metrics and settings. This comprehensive approach aims to provide a more accurate assessment of code LMs' performance in real-world conditions.

**Benchmark (基准):** **用来测量、评估或比较性能的标准或基准。**科研中的“尺子”。大家都在这个数据集上跑分，谁高谁就厉。这篇论文就是说之前的“尺子”是弯的，我造了一把直的。

**Human-verified (人工核验):** 金标准。通常自动标注不准，人工看最准，但人工太贵太慢。作者声称他们的方法既快（自动）又准（接近人工）。

**Chronological Data Splitting (按时间划分):** 这是一个高级且科学的划分方法。

- *普通做法:* 随机抽80%做训练，20%做测试。
- *问题:* 可能用2023年的代码训练，去预测2020年的漏洞（穿越了）。
- *本文做法:* 用2022年以前的代码训练，测2023年的代码。这更符合现实（Past predicting Future）。

Evaluating code LMs on PrimeVul reveals that existing benchmarks significantly overestimate the performance of these models. For instance, a state-of-the-art 7B model **scored 68.26% F1 on BigVul but only 3.09% F1 on PrimeVul**. Attempts to improve performance through advanced training techniques and larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akin to random guessing in the most stringent settings. These findings underscore the considerable gap between current capabilities and the practical requirements for deploying code LMs in security roles, highlighting the need for more innovative research in this domain.

- **F1 Score:** 评估模型好坏的核心指标。它是**Precision（查准率）和 Recall（查全率）**的调和平均数。

                                          $F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

 Precision (查准率/精确率)：

- **通俗解释：** 模型说是漏洞，实际上真的是漏洞的比例。
- **宁缺毋滥：** 如果 Precision 低，说明模型在“狼来了”，误报（False Positive）太多，安全专家会累死在核查假警报上。

Recall (查全率/召回率) ：

- **通俗解释：** 在所有真实存在的漏洞中，模型成功抓住了多少。
- **宁可错杀一千，不可放过一个：** 如果 Recall 低，说明漏报（False Negative）太多，漏洞溜进了产品，后果严重。

*分数解读:* 68% 意味着模型通常能用；**3% 意味着模型基本在瞎猜**。

**意义:** 这个巨大的落差（68% -> 3%）直接证明了之前的研究严重高估了AI的能力。**这是这篇Paper最大的亮点。**

### **Motivation（研究动机 / 为什么要做）**

现有漏洞检测数据集存在严重问题，会导致模型表现被高估：

1. **数据质量极差 (Noisy Labels): 把“没漏洞的代码”标记成“有漏洞”。**
- **问题：** 现有数据集（如 BigVul, CodeXGLUE）过度依赖*自动化的“漏洞修复 Commit”来打标签* 。
- **后果：** 很多 Commit 包含重构、格式修改等非安全内容，导致大量“假阳性”数据 。人工检查发现 CodeXGLUE 只有 **24%** 的标签是对的 。

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image.png)

       (Page4)

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image%201.png)

(Page14)

***自动化打标原理（旧方法）：** 以前的研究者（比如 BigVul 的作者）写脚本去爬取这些 Commit。他们的逻辑非常简单粗暴：*

- ***Commit 之前**的代码 = **有漏洞的代码 (Vulnerable)**。*
- ***Commit 之后**的代码 = **安全的代码 (Benign)**。*
- *他们认为这个 Commit 里修改的**每一个函数**都是在修漏洞 。*

***Noisy labels:** In VD literature, researchers typically label datasets either automatically or manually.**Most large datasets [4, 5, 9] use automatic labeling because manual labeling is too expensive.However, automatic labeling can introduce significant label noise.**For instance, datasets like BigVul [9] curate hundreds of thousands of functions from the real world and rely on vulnerability-fixing commits for labeling.However, they suffer from a flawed assumption that each function modified by such a commit corresponds to a (separate) vulnerability.In practice, vulnerability-fixing commits often fix one vulnerability but also make other changes to surrounding code, and existing automatic labeling methods **wrongly label that surrounding code as vulnerable.**In contrast, manual labeling offers higher accuracy, but its cost means it can only be applied to smaller datasets.For instance, the most accurate prior dataset, SVEN [12], which was manually labeled, covers only 9 Common Weakness Enumerations (CWEs) and comprises only 1.6k samples. (Page1 )*

*…they label the before-commit version of changed functions as vulnerable, and their after-commit version and unchanged functions as nonvulnerable.(Page 3 Automated Labeling L8-L10)*

1. **数据严重泄露 (Data Leakage):**
- **问题：** 训练集和测试集存在大量重复代码（Exact Copies）
- 类型：*代码复制（Code Copy）*和 *时间穿越（Time Travel）*
    
    ***定义：** 也就是测试集里的代码，已经在训练集里出现过了 。*
    
    *C. Data Leakage
    Data leakage has been identified as a significant issue in the area of machine learning for code. We consider two types of leakage: **code copy and time travel.***
    

***为什么会出现大量重复代码？***

**1.代码特性：** 源代码本身就具有高度的**重复性** 。开源社区里大家经常互相 Copy-Paste，导致很多函数在不同的项目里长得一模一样。

*Code Copy: One main reason for leakage is data duplication [30] since code data is highly repetitive [31, 32], and LMs are known to be good at memorizing the code text [33]. Specifically, leaking exact copies across the training and evaluation set will inevitably inflate the evaluation performance.(Page 4 [C.Data](http://C.Data) Leakage-Data Spilts-1 )*

**2.去重不彻底：** 之前的研究者（比如 DiverseVul 的作者）虽然试图用哈希值去重，但他们没有处理**格式差异**（比如空格、换行）。

- 只要加个空格，MD5 哈希值就变了，旧方法就以为这是段新代码。
- 但这篇论文的作者做了**归一化处理**（去除空格、换行等），发现即使只是格式不同，核心代码逻辑依然是完全一样的 。

*Interestingly, we notice that, with hash-based deduplication, DiverseVul still has 3.3% copies. This is mainly because they did not normalize formatting characters, and the same code with varied spacing will be mapped to distinct MD5 hashes, failing to be identified as copies.(Page4 Results L5-L8)*

- **后果：** 某些基准测试(CVEFixes)中，**18.9%** 的测试样本直接泄露自训练集 。模型是在“背题”而非“做题”。

*This is particularly problematic when one copy appears in the training set and another copy in the testing set, as performance metrics become unrepresentative of real-world performance and misrepresent the model’s ability to generalize to unseen data. We found that up to 18.9% test samples are leaked from the train set in some bechmarks.(Page2 L4-L10)*

**严重性：**

- 大语言模型（LLMs）最擅长的就是**记忆** 。
- 如果有 20% 的题是送分题，那么模型的准确率起步就是 20%，这让评估结果完全失去了参考价值，掩盖了模型真实的推理能力 。
- 这也是为什么作者要提出 **PRIMEVUL**，因为在这个新数据集里，通过严格去重，这一比例降到了 **0.0%** 。

*Data duplication: Furthermore, data duplication is prevalent in these datasets. Our analysis identified significant levels of exact copies and cloned vulnerabilities within the datasets. This is particularly problematic when one copy appears in the training set and another copy in the testing set, as performance metrics become unrepresentative of real-world performance and misrepresent the model’s ability to generalize to unseen data. We found that up to 18.9% test samples are leaked from the train set in some benchmarks.（Page2 Para 1)*

1. **评估脱离现实 (Unrealistic Evaluation):**
- **问题：**
    
    **1）随机切分 (Random Split):** 导致用未来的数据测过去的数据（*Time Travel*）。
    
    - **常规做法的问题：** 普通的随机切分打乱了时间顺序 。
    - **核心概念 (Time Travel)：** 如果随机切分，你很可能把 **2023年** 的代码分到了训练集，把 **2020年** 的代码分到了测试集。
    - **后果：** 这就相当于模型拿着“未来的知识”去预测“过去的数据” 。因为开发者修复 Bug 的模式是会演进的，同一个 Commit 里修复多个相似漏洞的情况也很常见，随机切分会导致模型在训练时就见过了测试集里那个 Commit 的其他部分，从而泄露了信息 。
    - **正确做法：** 必须按*时间切分（Chronological Split）*，只能用过去的数据训练，预测未来的数据 。
    
    *2)**Time Travel**: Existing datasets also have the issue of time travel since they randomly separate functions into train, validation, and test sets(训练集、验证集、测试集）. Consequently, it is possible to train on future data and test on past data. It is also possible to have the fixed nonvulnerable function in the training set, and the older vulnerable function in the test set.(Page 5 Para1)*
    
    *However, training and testing with samples from the same commit is unrealistic and leaks information from the test time to the training time. In a realistic setting, the models are trained on the historical data to predict future samples.(Page 5 Para2 L7-Final)*
    
    **2）比例失真:** 强行构造 1:1 的正负样本，忽视了现实中漏洞极度稀缺（Base Rate Problem）。
    
    - **实验室环境 (The Lab)：** 为了方便模型训练，以前的研究者通常会构造一个比较平衡的数据集（比如有漏洞和没漏洞的样本比例接近，或者人为平衡过），让你感觉随便猜都有 50% 的胜算。
    - **真实环境 (Reality)：** 在真实软件开发中，漏洞是非常**稀缺**的（Rare） 。绝大多数代码（比如 99.9%）都是安全的。
    - **Base Rate Problem：** 指的就是这种“实验室里的高比例”和“现实中的极低比例”之间的巨大**不匹配 (mismatches)** 。在这种不匹配下训练出来的模型，会对现实世界里的低概率事件（漏洞）产生错误的判断倾向。
    
    *Accuracy: Many benchmarks report accuracy scores, but accuracy is not an appropriate metric for vulnerability detection, because of the **base rate problem** (vulnerabilities are rare in practice; most code is not vulnerable) and because of mismatches in class balance (the proportion of vulnerable samples in most research datasets does not match the ratio of vulnerable code in real life).(Page2 Limitation in existing evaluation metrics L4-)*
    
    **3）指标失效:** F1 Score 掩盖了高误报率的问题 。
    
    - ***F1 的定义*：** 它是查准率和查全率的调和平均数 。它把“漏报”（False Negative）和“误报”（False Positive）看作是同等重要的惩罚 。
    - **现实的痛点：** 现实中安全代码是**绝大多数 (overwhelming majority)**
        - 如果模型有 **1% 的误报率**。
        - 在 1000 行代码里（假设只有 1 个真漏洞），这 1% 的误报率会产生 **10 个假警报**。
        - 程序员要处理 10 个假警报才能找到 1 个真漏洞，这会导致严重的**警报疲劳 (Alert Fatigue)** 。
        
        *This dual expectation(平衡假阳性（false positives）和假阴性（false negatives） reflects the practical tradeoffs in software development: missed vulnerabilities can lead to security breaches, while too many false alarms can lead to alert fatigue, potentially causing real issues to be ignored. F1 and accuracy offer little insight into the tradeoff between false negatives and positives.(Page 5 Detection Error Tradeoffs L6-L11)*
        
    
    - **结论：** F1 Score 看不到这种不对称性 。一个 F1 分数很高的工具，如果误报太多，在实践中也是**没用的 (useless)** 。

*F1: While the F1 score is widely perceived to be a better metric for assessing classification performance on imbalanced datasets, we argue that it is not appropriate in reality either.The F1 score (the harmonic mean of precision and recall) reflects both false positives and false negatives by combining them into a single penalty. Yet, **for VD tools in practice, the overwhelming majority of code is not vulnerable**, so a critical challenge is preventing excessive false alarms.The F1 score fails to reflect this asymmetry, so tools with a high F1 score may be useless in practice.(Page 2)*

---

### **Approach（方法）**

### **1. 建立新数据集 PRIMEVUL**

**具体方法：**

**1）严格标注规则（Strict Labeling Criteria）**

作者先收集了 BigVul, CrossVul, CVEfixes 等一堆旧的“脏”数据集放在一起 ，再设计了两个过滤器，确保数据不是Noisy Labels:

① PRIMEVUL-ONEFUNC (针对单函数修改)

- 避免 “commit message + 靠调用链推断” 导致的误标。
- **新规则：** 只收录那些“仅仅修改了一个函数”的 Commit。只有函数本身能独立造成安全风险才被标为漏洞。
- **为什么这么做？** 如果一个 Commit 只动了一个函数，那么这个函数大概率就是漏洞所在，几乎没有“连带修改”或“重构”的干扰。这极大提高了准确率。

*PRIMEVUL-ONEFUNC: We notice that the previous labeling method has errors particularly when dealing with commits that modify multiple functions. Therefore, PRIMEVUL-ONEFUNC regards a function as vulnerable if it’s **the only** function changed by a security-related commit.(Page 5)*

② PRIMEVUL-NVDCHECK (针对 CVE 描述校验)

- **原理：** 利用权威的 **NVD（国家漏洞数据库）**。每个 CVE 漏洞都有详细的文字描述（比如“`login.c` 文件中的 `auth` 函数存在溢出”）。

1) 什么是 ***CVE***?

- 通用漏洞披露 (Common Vulnerabilities and Exposures)
    - **通俗解释：** 它是全球通用的**“漏洞身份证号”**。
    - **作用：** 世界上每天都会发现成百上千个新漏洞。为了不让大家搞混（比如“那个 Windows 的漏洞”到底是哪个？），安全界给每一个被确认的漏洞分配一个唯一的编号。
    - **格式：** `CVE-年份-编号`。
        - 例如：`CVE-2021-44228` (著名的 Log4j 漏洞)。
    - **在论文中的角色：** 作者利用这个编号，把代码库里的 `Commit`（代码修改记录）和具体的“安全事件”对应起来 。

2) 什么是 ***NVD***？

- 国家漏洞数据库 (National Vulnerability Database)
    - **通俗解释：** 它是美国政府（NIST）维护的**“漏洞详细档案库”**。
    - **关系：** 如果说 CVE 只是一个“身份证号”，那么 NVD 就是这个号码对应的**“详细体检报告”**或**“个人档案”**。
    - **新规则：** 拿代码里的函数名去跟 NVD 的描述做**文本匹配**。
        - 只有当 NVD 描述里**明确写出了这个函数的名字**，或者写出了文件名且该文件只改了一个函数时，才算数。
    - **为什么这么做？** 这是用“专家知识”（CVE 描述）来验证“代码变更”，相当于请了安全专家来做自动审核。
    - **档案里有什么？**
        - 漏洞的严重程度打分 (CVSS Score)。
        - 受影响的软件版本。
        - **漏洞描述 (Description)：** 这是这篇论文用到的核心！这里会有一段专家写的文字，详细解释漏洞发生了什么，比如：“在 `login.c` 文件的 `auth_user` 函数中存在缓冲区溢出漏洞...” 。

*PRIMEVUL-NVDCHECK: Since human experts have analyzed the CVEs in the NVD database, **the vulnerability description** in each CVE entry is a reliable reference to label vulnerable functions. We develop PRIMEVUL-NVDCHECK as
the following. First, we link security-related commits to their CVE numbers and the vulnerability description in the NVD database. We label a function as vulnerable if it satisfies one of the two following criteria: (1) NVD description explicitly mentions its name, or (2) NVD description mentions its file name, and it is the only function changed by the security-related commit in that file.(Page 5)*

**2）**覆盖 **140 种 CWE（Common Weakness Enumeration，通用弱点枚举）**。

**CWE (Common Weakness Enumeration):**

- 释义： CWE 是一个国际通用的、社区开发的**软件安全缺陷分类标准**， 它是国际通用的**“漏洞分类字典”**。
- 作用：它为已知的软件和硬件弱点提供了一个通用语言，方便安全专家、开发者和工具之间进行沟通和分类。例如，`CWE-89` 指的是“SQL 注入”，`CWE-119` 指的是“限制操作缓冲区边界不当”

**论文的突破：**

- 之前最好的手动数据集 SVEN 只包含 **9 种** CWE（样本太单一）。
- PRIMEVUL 覆盖了 **140 种** CWE。（采用了“高精度自动化筛选”的方法，并依赖权威数据库的专家知识）
    
    ***具体步骤：***
    
    1. **利用 NVD 数据库：** NVD（国家漏洞数据库）中的每一个 CVE（通用漏洞披露）条目都包含了由安全专家分析和撰写的详细漏洞描述 。
    2. **反向链接：** 作者将 GitHub 上的漏洞修复 Commit 链接到对应的 CVE 编号 。
        
        …*First, we link security-related commits to their CVE numbers and the vulnerability description in the NVD database. …*
        
    3. **精确匹配：** 然后，作者使用 NVD 中的官方漏洞描述作为**可靠的参考**，来判断 Commit 修改的函数是否真的与该漏洞相关 。(*就是第一点的PRIMEVUL-NVD ② 专家驱动的自动化方法*）
- **意义：**通过这种方法，作者能**大规模**地继承和利用 NVD 中已经存在的专家知识，从而筛选出涉及 **140 种** CWE 的样本，而不是只依赖少数几种常见的 CWE 。 这意味着模型能学到更全面、更丰富的漏洞类型，而不是只会做几种特定的题。

**3）**漏洞数据量比现有最准确数据集 **大 16.7×**。

- **对比对象：** **SVEN** 数据集（这是之前唯一的“高质量/人工标注”数据集，作为金标准）。

- SVEN  ：**“Security Hardening and Adversarial Testing”**，是一个相对较小但质量极高的数据集。
    - **身份 (Identity):** 它是以前所有漏洞检测数据集里，**标签准确率最高**的一个。
    - **方法 (Method):** SVEN 采用的是**纯手工标注** (manually labeled) 。
    - **过程：** 由人类安全专家逐个函数地去验证代码是否真的包含漏洞 。
    - **准确率：** SVEN 的标签准确率高达 **94%** 。
    - **局限性 (Limitation):** 正因为是纯手工标注，它有以下两个缺点：
        1. **规模小：** 只包含大约 **1.6k 个样本** 。
        2. **多样性低：** 仅覆盖 **9 种**常见的弱点枚举（CWEs） 。
    
    *For instance, the most accurate prior dataset, SVEN [12], which was manually labeled, covers only 9 Common Weakness Enumerations (CWEs) and comprises only 1.6k samples.(Page 1 )*
    
    *As shown in Table I, the benchmarks without manual verification have very low accuracy between 25% and 60%,for vulnerable functions. On the other hand, only one out of the three prior datasets.On the other hand, only one out of the three prior datasets that used manual labeling method has a high accuracy: SVEN has a 94% label accuracy for vulnerable functions. (Page 4)*
    
    - **对比对象：** SVEN 出现之前，大部分数据集（如 CodeXGLUE）依赖自动化标注，标签准确率只有 24% 到 60% 。
- **PRIMEVUL 的突破：**
    - 通过 **NVDCHECK** 等高精度自动化规则，PRIMEVUL 成功地以**自动化**的方式，达到了与 SVEN **纯手工标注相似的准确率** 。
    - 同时，PRIMEVUL 样本量是 SVEN 的 **16.7 倍** ，CWE 覆盖数是 SVEN 的 **15.6 倍**（140 vs 9） 。
    - **意义：** 解决了“高质量”和“大数据”不可兼得的矛盾（The Dichotomy）。
    
    *To this end, PRIMEVUL contains 6,968 vulnerable and 228,800 benign functions, covering 140 CWEs while maintaining similar accuracy as SVEN, marking a substantial advancement in both scale and accuracy compared to previous datasets*.
    

### **2. 数据去重（Deduplication）与时间切分（Temporal Split）**

### ****1）数据去重 (Thorough Data De-duplication)

为了解决之前提到的 **Data Leakage（数据泄露）** 问题中的第一种***代码复制(Code Copy)***，确保模型不是在“背题”。

- 方法：**基于归一化的去重 (Normalization-based De-duplication)**
- **具体手段：** **归一化 (Normalization) + MD5 哈希**
    - 在计算哈希前，先剔除代码中的所有**格式字符**（空格、Tab、换行符）。
    - 也就是把代码“压缩”成一行纯字符，再算 MD5 。
    
    **解决的问题：**
    
    - 消除“仅有格式差异” (Formatting Differences) 的重复代码 。
    - 防止“逻辑完全一样，只是排版/缩进不一样”的代码同时出现在训练集和测试集中，造成数据泄露。
    
    *We de-deduplicate code copies as well as functions with only formatting differences. For each commit, we first normalize the changed functions before and after commits by stripping away characters such as spaces, tabs (“\t”), newline characters (“\n”), and carriage return characters (“\r”). Then we compute the MD5 hash of both the pre- and post-commit versions of the changed function. If the pre- and post-commit versions of a function result in identical hash values, we regard this function as unchanged and discard it.（消除仅有格式差异的重复代码） Finally, we combine all    remaining functions, and further de-duplicate the whole set by the MD5 hashes of the normalized functions. During the de-duplication, we maintain a unique set of hashes. If the hash of a normalized function is already in the set, we exclude it from further processing.(Page 5 III A Para2)*
    
    ｜两次去重：
    
    1.第一次：比较修改前(Pre-commit)和修改后(Post-commit)的代码，归一化后的哈希值一样，去掉这个代码；
    
    2.第二次：比较总集合里做完第一次去重后不同的项目的代码，删去相同的代码
    
- 什么是哈希值 (Hash Value)?
    - **通俗定义:** 数据的**“数字指纹”**。
    - **特性:**
        - **唯一性:** 不同的代码内容，算出来的哈希值（指纹）几乎肯定不同。
        - **确定性:** 只要代码内容完全一样，算出来的哈希值永远一样。
        - **不可逆:** 看到哈希值无法推导出原始代码（就像看到指纹还原不出长相），但在去重场景中我们只需要对比指纹是否相同。
- 什么是 MD5?
    - **定义:** 一种具体的哈希算法 (Message-Digest Algorithm 5)。
    - **输出格式:** 无论输入代码有多长，MD5 都会输出一个固定长度的 **32位 16 进制字符串**。
    - **例子:**
        - 输入: `"print('hello')"`
        - 输出 (MD5): `e358efa489f58062f10dd7316b65649e`

### 2）按时间切分 (Temporal Split)

为了解决之前提到的 **Time Travel（时间穿越）** 问题，模拟真实的软件开发场景。

- 方法
    
    作者放弃了传统的随机切分（Random Split），采用了**严格的时间轴切分**。
    
- **第1步：绑定时间**找到每个样本对应的原始 **Commit Date (提交日期)** 。
- **第2步：全量排序**把所有样本按照提交时间从旧到新排序 。
- **第3步：按比例切分**
    - **Train (训练集):** 最早的 **80%** 数据（过去的数据）。
    - **Validation (验证集):** 中间的 **10%** 数据 。
    - **Test (测试集):** 最新的 **10%** 数据（未来的数据）。
- **关键约束 (约束条件):**
    
    **同一个 Commit 里的所有样本必须在同一个集里** 。不能出现“同一个补丁修了3个文件，2个进了训练集，1个进了测试集”的情况，这也是为了防泄露。
    
    - 原因：
        
        一个 Commit 往往是修补同一个逻辑的漏洞，涉及的多个文件之间高度相似 。
        
    
    *A. Temporal Splits
    To minimize the data leakage issue and formulate a realistic train-evaluate setup for vulnerability detection, we split the train(训练集)/validation(验证集)/test(测试集) set of PRIMEVUL according to the commit date of the samples. Concretely, we find the original commit for each sample and collect the time of that commit, tying it with the sample. Then, we sort the samples according to the commit, where the oldest 80% will be the train set, 10% in the middle will be the validation set, and the most recent 10% will be the test set. We also make sure that the samples from the same commit will not be split into different sets. This ensures that the vulnerability detection model is trained using past data and tested over future data.(Page 6 IV A)*
    

### 为什么要这么做？

    为了实现 **"Past predicting Future" (用过去预测未来)** 。***模拟真实的软件开发环境。***
    在真实工作中，你只能用截至昨天为止学到的知识，去修今天新出现的 Bug。如果用随机切分，模型可能会用 2023 年的代码知识去修 2020 年的 Bug，这在逻辑上是作弊。

### **3. 新评测指标：VD-S（Vulnerability Detection Score）**

 1 ) 为什么要发明 VD-S？（F1 错在哪？）

- **现实残酷：** 在真实开发中，开发者最讨厌工具**“乱报警”**（Alert Fatigue）。如果一个工具每天报 100 个错，其中 99 个都是误报，开发者会直接卸载它 。
- **F1 的掩护：** *F1 Score 是 Precision **(查准率)**和 Recall **(查全*率)***的平均数*。即使误报率有点高，只要查全率高，F1 分数依然可以很高（比如 60-70%）。这**掩盖**了模型在现实中根本没法用的事实 。

*Detection Error Tradeoffs: Balance between false positives and false negatives is critical when deploying vulnerability detection tools. Developers rely on these tools not only to catch as many real vulnerabilities as possible (minimizing false negatives) but also to do so without overwhelming them with false alarms (minimizing false positives). This dual expectation reflects the practical tradeoffs in software development: missed vulnerabilities can lead to security breaches, while too many false alarms can lead to alert fatigue, potentially causing real issues to be ignored. F1 and accuracy offer little insight into the tradeoff between false negatives and positives.(Page 5 II D-1)*

2 )VD-S 具体怎么算？

**核心逻辑：先卡死查准率，再看查全率。**

- **定义：** VD-S 测量的是模型的 **漏报率 (False Negative Rate, FNR)**，但有一个极其严格的前提条件。
- **前提条件：** 模型的 **误报率 (False Positive Rate, FPR)** 必须被限制在一个极低的阈值以下（论文中设定为 **0.5%**） 。
- **指标：** 测量的指标是 **漏报率 (FNR)** 。
- **含义：**漏报率越低（说明查出来的越多），VD-S 分数越好越小。
- ***调节（Tuning）过程：***
为了满足 **FPR ≤ 0.5%** 这个死命令，评测者会不断**提高门槛**。
    - 如果 50% 门槛时，误报率是 5%（太高了，不行）。
    - 那就把门槛提到 90%，误报率降到 1%（还不行）。
    - 那就提到 99.9%，误报率终于降到 0.5% 了（达标！）
    - **VD-S 的数值是 FNR（漏报率）**，所以**数值越大，代表表现越差**
- **旧方法 (F1)：** 找一个“误报”和“漏报”的平衡点。
**新方法 (VD-S)：** 我们不要平衡。我们的要求是：
    
    **1.前提：** 你的“误报”必须非常非常少（`FPR 小于等于0.5%`）。
    
    **2.目标：** 在满足前提1的工具里，谁能把“漏报”（`FNR`）降到最低，谁就是最好的。
    
    *To this end, we propose Vulnerability Detection Score (VD-S), that evaluates the False Negative Rate of a vulnerability detector within an acceptable False Positive Rate, i.e., FNR @ (F P R ≤ r), where r ∈ [0%, 100%] is a configurable parameter. In this paper, we choose a tolerance rate r = 0.5% to perform the evaluation in Section V.(Page 6 IV B Para2)*
    

### **4. Pair-wise Evaluation（成对评测）**

1）核心逻辑：构造 “漏洞版本（Buggy） vs 修复版本（Patched）” 的代码对：

- **代码 A (Vulnerable):** 有漏洞的原始版本。
- **代码 B (Patched):** 程序员修复后的安全版本。
- **特点：** 这两段代码通常只有一行甚至几个字符的区别（比如把 `strcpy` 改成了 `strncpy`），文本相似度极高（论文要求相似度 > 80%）。

*Concretely, we match the vulnerable functions with their patches in PRIMEVUL to construct such pairs. As we show in Table III, the paired vulnerable functions are fewer than all vulnerable functions, since not all vulnerable functions have a patch (e.g.,a patch could delete the vulnerable function), and we only include those challenging pairs sharing at least 80% of the string between the vulnerable and benign version.(Page 6 IV-2 Para2)*

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image%202.png)

- **测试规则：** 把这两段代码同时扔给模型，看它能不能**准确区分**：A 是坏的，B 是好的。

*Paired Functions and Pair-wise Evaluation: As discussed in Section II-D2, evaluating the models on paired functions—vulnerable and benign versions of code—could potentially reveal whether a model merely relies on superficial text patterns to make predictions without grasping the underlying security implications, indicating areas where the model needs improvement to reduce the false positives and false negatives.(意思是：这能揭穿模型是不是只靠肤浅的文本模式在“猜”，而没有真正理解安全含义。)*

2） 四种可能的结局 (The 4 Outcomes)

为了量化模型到底有多“瞎”，作者定义了四种预测结果。理解这四个指标，你在看实验结果图表时就会非常清晰。

- **✅P-C (Pair-wise Correct): 完全正确**
    - 模型说：A 是漏洞，B 是安全。
    - **含义：** 模型真的懂了，它看出了那一点点修复带来的变化。这是我们追求的目标。
- **⚠️ P-V (Pair-wise Vulnerable): 盲目激进**
    - 模型说：A 是漏洞，**B 也是漏洞**。
    - **含义：** 模型只看长相。因为它觉得 A 和 B 长得像，所以认为它俩都是坏的。这说明模型分不清“修复前”和“修复后”。
- **💤 P-B (Pair-wise Benign): 盲目乐观**
    - 模型说：**A 是安全**，B 也是安全。
    - **含义：** 模型根本没发现漏洞，全放跑了。
- **❌ P-R (Pair-wise Reversed): 颠倒黑白**
    - 模型说：A 是安全，**B 是漏洞**。
    - **含义：** 模型完全搞反了逻辑，这比瞎猜还糟糕。
    
- **关键发现:** GPT-4 也无法通过此项测试，证明 LLM 尚未真正理解安全逻辑。

---

## **Research Questions（研究问题，RQ）**

**RQ1：现有漏洞检测数据集质量到底如何？**

→ 作者系统性分析了 BigVul/Devign 的标签质量、重复率与数据泄露。

**RQ2：在更真实的数据集（PrimeVul）上，现有 Code LMs 表现如何？**

→ 评估 7B、13B、GPT-3.5、GPT-4 等模型。

**RQ3：更大模型或更强训练方法能否解决问题？**

→ 尝试微调、指令调优、对比训练等。

**RQ4：使用新指标和成对评测，模型是否能真正理解漏洞？**

→ 测试漏洞语义理解能力。

---

## **Results（主要结果）**

### **1. 当前模型在严格数据集上的表现接近随机**

- StarCoder2, 7B参数：
    - BigVul：**68.26% F1**
    - PRIMEVUL：**3.09% F1**
        
        说明原有评估体系严重高估模型能力。
        
        **关键结论：** 现有的 Benchmark 严重高估（Overestimate）了模型的能力。
        

### **2. GPT-3.5 / GPT-4 表现也大幅下降**

- 在严格的 PRIMEVUL + 新指标 VD-S 下，效果接近随机。
- 特别是在 **Pair-wise Evaluation**环节，GPT-4 即使加了 **Chain-of-Thought (思维链)**，表现也**不如随机猜测** 。
- 说明现在的 LLM 更多是靠**“文本相似度”**在判断，而不是真正理解了**“安全语义”**。面对长得极像的“漏洞版 vs 修复版”，GPT-4 也分不清。

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image%203.png)

*However, we realize that such performance is actually no better than a random guess since the majority of the pairs in PRIMEVUL still cannot be distinguished by these large SOTA code LMs, which might indicate the fundamental weaknesses of code LMs to differentiate subtle vulnerabilities from their benign versions.(Page 9)*

### **3. 先进训练手段（对比学习、pair-wise fine-tune 等）也无法显著提升性能**

- **现象：** 作者尝试用 **Class Weights（类别加权）** 解决样本不平衡，用 **Contrastive Learning（对比学习）** 增强区分度。
    - 类别加权：
        - **背景：** PRIMEVUL 数据集中，漏洞非常稀少，漏洞与安全样本的比例约为 **1:32** 。
        - **做法：** 作者尝试给漏洞类别加了 **5倍、20倍、30倍** 的权重 ，希望模型能多抓住几个漏洞。
        - **结果：** F1 分数确实稍微高了一点点，但在 VD-S（严苛模式）下，模型依然很难用 。说明这种“改分值”的手段救不了根本问题
        
    - 对比学习
        - **做法：** 作者借鉴了 SimCSE 等技术，使用了 **CA-CLR (Class-aware Contrastive Learning)** 。目的是想让模型把“有漏洞”和“没漏洞”的代码在语义上分得更开。
        - **结果：** 并没有显著提升 。
        - **结论：** 即使教了模型“找不同”，它还是看不出漏洞和修复版之间的本质区别，说明模型**对安全语义理解不够** 。
        
        *Findings-RQ2.2: Contrastive learning fails to significantly improve Code LMs’ performance on PRIMEVUL: Unfortunately, as shown in Table VII, we could not see a significant difference by adding the CLR objective. We further analyze the results to see what might go wrong. One notable misalignment we notice is that, since CLR from Gao et al. [40] is not crafted for classification tasks, it will distinguish any two samples regardless of whether their labels are the same. **Therefore,we further improve CLR to be a second approach, called Class-aware Contrastive Learning (CA-CLR), which will only minimize the similarity between samples with different labels.***
        
        - 2. CA-CLR 是什么？（升级版逻辑）
            
            **全称：** **C**lass-**A**ware **C**ontrastive **L**earning **R**epresentation（类别感知对比学习）。
            
            - **核心改进：** 给对比学习**“开了天眼”**，让它能看到**标签（Label）**。
            - **工作原理：**
                - 不再盲目地排斥所有“别人”。
                - **只排斥异类：** 只有当两个样本的**标签不同**（一个是漏洞，一个是安全）时，才把它们推远（最小化相似度） 。
                - **拉近同类：** 隐含的逻辑是，如果标签相同，就应该离得近一点。
            
            3. 结果怎么样？（依然悲剧）
            
            - **对比 SimCSE：** CA-CLR 的效果确实比 SimCSE 好了一些（F1 和 P-C 指标都有提升），证明引入标签是有用的 。
            - **最终结局：** 但是！提升依然是**微不足道（Marginal）**的 。
            - **深度解读（核心结论）：** 这说明了一个残酷的事实——代码大模型（Code LMs）根本就**没学会识别漏洞的模式**。哪怕你用 CA-CLR 强行拉大异类样本的距离，模型还是分不清，因为它根本看不懂漏洞代码的内在逻辑，只是在做简单的文本匹配 。
        - 什么是 SimCSE？
            
            **全称：** **Sim**ple **C**ontrastive **L**earning of **S**entence **E**mbeddings（句子嵌入的简单对比学习）。
            
            **核心原理：用“Dropout”做个分身**
            
            - **通俗比喻：** 想象你照镜子。镜子里的你和真实的你，虽然左右相反或有一点点光线差异，但本质上都是**同一个你**。
            - **技术实现：**
                - SimCSE 不需要额外的数据增强（比如把单词替换掉、把句子改写）。
                - 它利用神经网络自带的 **Dropout（随机失活）** 机制。
                - **操作步骤：**
                    1. 把同一段代码输入模型 **两次**。
                    2. 因为模型里有 Dropout（随机关掉一些神经元），这两次输出的向量（特征表示）会有一点点微小的差别，就像两个“分身”。
                    3. **训练目标：** 强迫模型承认这两个“分身”是**同一回事**（拉近它们的距离），同时把它们和其他代码的向量推远 。
        
        - 2. 论文里为什么要提 SimCSE？
            
            作者在 **RQ2**（尝试改进模型）中使用了这个技术作为**基础对照组**。
            
            - **目的：** 作者希望通过 SimCSE 这种方法，让模型学出更鲁棒（Robust）的代码特征，不仅仅是死记硬背文本。
            - **结果（失败了）：** 论文发现直接用 SimCSE 效果并不好 。
            - **失败原因：**
                - SimCSE 是“自恋”的：它只知道“我自己”和“我的分身”是一伙的。
                - 它**不知道类别（Label）**：它不管这段代码是“有漏洞”还是“安全”的，它只在乎自己和自己像不像 。
                - **后果：** 这对于分类任务（区分漏洞 vs 安全）帮助不大。
- **结果：** 提升非常微弱（Marginal improvements）。
- **解读：** 这说明问题的根源不在于训练技巧，而在于模型**根本没学会**怎么找漏洞。这个任务的难度(Hardness)远超预期。

### **4. PRIMEVUL 标签准确率 ≈ 人工审查级别，规模远大于同类数据集**

- **现象：** 这一条其实是对 Method 的验证。PRIMEVUL 的标签准确率（~92%）跟人工标注的 SVEN（94%）持平，但数据量是 SVEN 的 **16.7倍** 。
- **解读：** 这证明作者提出的“自动化清洗方法”是成功的，PRIMEVUL 是一个**“又大又准”**的新一代基准。