# Vulnerability Detection with Code Language Models: How Far Are We?

Authors: Yangruibo Ding; Yanjun Fu; Omniyyah Ibrahim; Chawin Sitawarin; Xinyun Chen; Basel Alomair; David Wagner; Baishakhi Ray; Yizheng Chen
Venue: ICSE 2025
Year: 2025
Topic / Keywords: Vulnerability Detection（漏洞检测）
Dataset Quality（数据集质量）Temporal Split（时间切分）Deduplication（去重）
Benchmark（基准评测）
Category: Benchmark
Link: https://arxiv.org/abs/2403.18624
Status: Reading
My Takeaway: 现有代码漏洞检测数据集质量低且存在数据泄露，使模型性能被严重高估；PrimeVul 通过更准确标注、严格去重与时间切分揭示出当前模型在真实场景中几乎失效，说明漏洞检测领域亟需更可靠基准与更强模型。

Abstract：

In the context of the rising interest in **code language models (代码大语言模型)**(code LMs) and **vulnerability detection(VD, 漏洞检测)**, we study the effectiveness of code LMs for detecting vulnerabilities. Our analysis reveals significant shortcomings in existing vulnerability datasets, including poor data quality, low label accuracy, and high duplication rates, leading to unreliable model performance in realistic vulnerability detection scenarios. Additionally, the evaluation methods used with these datasets are not representative of real-world vulnerability detection.

**Code LMs (Code Language Models, 代码大语言模型):** 专门在代码语料上训练的大模型，比如 GitHub Copilot 背后的 Codex，或者 CodeLlama。

**Vulnerability Detection (VD, 漏洞检测):** 指使用工具自动扫描代码，找出其中可能被黑客利用的Bug（如SQL注入、缓冲区溢出）。这是网络安全和软件工程的交叉领域

**Shortcomings (缺陷):** 作者指出了当前学术界的三大痛点：

- **Data Quality:** 很多代码片段是不完整的。
- **Label Accuracy (标签准确度):** 很多被标记为“有漏洞”的代码其实是没问题的（假阳性），反之亦然。
- **Duplication (数据泄露/重复):** 训练集和测试集里有一样的代码，就像考试前把答案背下来了，考试成绩虚高。

To address these challenges, we introduce **PrimeVul**, a new dataset for training and evaluating code LMs for vulnerability detection. PrimeVul incorporates a novel set of data labeling techniques that achieve comparable label accuracy to **human-verified benchmarks** while significantly expanding the dataset. It also implements a rigorous data de-duplication and **chronological data splitting** strategy to mitigate **data leakage** issues, alongside introducing more realistic evaluation metrics and settings. This comprehensive approach aims to provide a more accurate assessment of code LMs' performance in real-world conditions.

**Benchmark (基准):** **用来测量、评估或比较性能的标准或基准。**科研中的“尺子”。大家都在这个数据集上跑分，谁高谁就厉。这篇论文就是说之前的“尺子”是弯的，我造了一把直的。

**Human-verified (人工核验):** 金标准。通常自动标注不准，人工看最准，但人工太贵太慢。作者声称他们的方法既快（自动）又准（接近人工）。

**Chronological Data Splitting (按时间划分):** 这是一个高级且科学的划分方法。

- *普通做法:* 随机抽80%做训练，20%做测试。
- *问题:* 可能用2023年的代码训练，去预测2020年的漏洞（穿越了）。
- *本文做法:* 用2022年以前的代码训练，测2023年的代码。这更符合现实（Past predicting Future）。

Evaluating code LMs on PrimeVul reveals that existing benchmarks significantly overestimate the performance of these models. For instance, a state-of-the-art 7B model **scored 68.26% F1 on BigVul but only 3.09% F1 on PrimeVul**. Attempts to improve performance through advanced training techniques and larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akin to random guessing in the most stringent settings. These findings underscore the considerable gap between current capabilities and the practical requirements for deploying code LMs in security roles, highlighting the need for more innovative research in this domain.

- **F1 Score:** 评估模型好坏的核心指标。它是**Precision（查准率）和 Recall（查全率**的调和平均数。

                                          $F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

 Precision (查准率/精确率)：

- **通俗解释：** 模型说是漏洞，实际上真的是漏洞的比例。
- **宁缺毋滥：** 如果 Precision 低，说明模型在“狼来了”，误报（False Positive）太多，安全专家会累死在核查假警报上。

Recall (查全率/召回率) ：

- **通俗解释：** 在所有真实存在的漏洞中，模型成功抓住了多少。
- **宁可错杀一千，不可放过一个：** 如果 Recall 低，说明漏报（False Negative）太多，漏洞溜进了产品，后果严重。

*分数解读:* 68% 意味着模型通常能用；**3% 意味着模型基本在瞎猜**。

**意义:** 这个巨大的落差（68% -> 3%）直接证明了之前的研究严重高估了AI的能力。**这是这篇Paper最大的亮点。**

### **Motivation（研究动机 / 为什么要做）**

现有漏洞检测数据集存在严重问题，会导致模型表现被高估：

1. **数据质量极差 (Noisy Labels): 把“没漏洞的代码”标记成“有漏洞”。**
- **问题：** 现有数据集（如 BigVul, CodeXGLUE）过度依赖*自动化的“漏洞修复 Commit”来打标签* 。
- **后果：** 很多 Commit 包含重构、格式修改等非安全内容，导致大量“假阳性”数据 。人工检查发现 CodeXGLUE 只有 **24%** 的标签是对的 。

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image.png)

       (Page4)

![image.png](Vulnerability%20Detection%20with%20Code%20Language%20Models%20/image%201.png)

(Page14)

***自动化打标原理（旧方法）：** 以前的研究者（比如 BigVul 的作者）写脚本去爬取这些 Commit。他们的逻辑非常简单粗暴：*

- ***Commit 之前**的代码 = **有漏洞的代码 (Vulnerable)**。*
- ***Commit 之后**的代码 = **安全的代码 (Benign)**。*
- *他们认为这个 Commit 里修改的**每一个函数**都是在修漏洞 。*

***Noisy labels:** In VD literature, researchers typically label datasets either automatically or manually.**Most large datasets [4, 5, 9] use automatic labeling because manual labeling is too expensive.However, automatic labeling can introduce significant label noise.**For instance, datasets like BigVul [9] curate hundreds of thousands of functions from the real world and rely on vulnerability-fixing commits for labeling.However, they suffer from a flawed assumption that each function modified by such a commit corresponds to a (separate) vulnerability.In practice, vulnerability-fixing commits often fix one vulnerability but also make other changes to surrounding code, and existing automatic labeling methods **wrongly label that surrounding code as vulnerable.**In contrast, manual labeling offers higher accuracy, but its cost means it can only be applied to smaller datasets.For instance, the most accurate prior dataset, SVEN [12], which was manually labeled, covers only 9 Common Weakness Enumerations (CWEs) and comprises only 1.6k samples. (Page1 )*

*…they label the before-commit version of changed functions as vulnerable, and their after-commit version and unchanged functions as nonvulnerable.(Page 3 Automated Labeling L8-L10)*

1. **数据严重泄露 (Data Leakage):**
- **问题：** 训练集和测试集存在大量重复代码（Exact Copies）。
    
    ***定义：** 也就是测试集里的代码，已经在训练集里出现过了 。*
    

*This is particularly problematic when one copy appears in the training set and another copy in the testing set, as performance metrics become unrepresentative of real-world performance and misrepresent the model’s ability to generalize to unseen data. We found that up to 18.9% test samples are leaked from the train set in some bechmarks.(Page2 L4-L10)*

***为什么会出现大量重复代码？***

**1.代码特性：** 源代码本身就具有高度的**重复性** 。开源社区里大家经常互相 Copy-Paste，导致很多函数在不同的项目里长得一模一样。

*Code Copy: One main reason for leakage is data duplication [30] since code data is highly repetitive [31, 32], and LMs are known to be good at memorizing the code text [33]. Specifically, leaking exact copies across the training and evaluation set will inevitably inflate the evaluation performance.(Page 4 [C.Data](http://C.Data) Leakage-Data Spilts-1 )*

**2.去重不彻底：** 之前的研究者（比如 DiverseVul 的作者）虽然试图用哈希值去重，但他们没有处理**格式差异**（比如空格、换行）。

- 只要加个空格，MD5 哈希值就变了，旧方法就以为这是段新代码。
- 但这篇论文的作者做了**归一化处理**（去除空格、换行等），发现即使只是格式不同，核心代码逻辑依然是完全一样的 。

*Interestingly, we notice that, with hash-based deduplication, DiverseVul still has 3.3% copies. This is mainly because they did not normalize formatting characters, and the same code with varied spacing will be mapped to distinct
MD5 hashes, failing to be identified as copies.(Page4 Results L5-L8)*

- **后果：** 某些基准测试(CVEFixes)中，**18.9%** 的测试样本直接泄露自训练集 。模型是在“背题”而非“做题”。

**严重性：**

- 大语言模型（LLMs）最擅长的就是**记忆** 。
- 如果有 20% 的题是送分题，那么模型的准确率起步就是 20%，这让评估结果完全失去了参考价值，掩盖了模型真实的推理能力 。
- 这也是为什么作者要提出 **PRIMEVUL**，因为在这个新数据集里，通过严格去重，这一比例降到了 **0.0%** 。

*Data duplication: Furthermore, data duplication is prevalent in these datasets. Our analysis identified significant levels of exact copies and cloned vulnerabilities within the datasets. This is particularly problematic when one copy appears in the training set and another copy in the testing set, as performance metrics become unrepresentative of real-world performance and misrepresent the model’s ability to generalize to unseen data. We found that up to 18.9% test samples are leaked from the train set in some benchmarks.（Page2 Para 1)*

1. **评估脱离现实 (Unrealistic Evaluation):**
- **问题：**
    
    **1）随机切分 (Random Split):** 导致用未来的数据测过去的数据（*Time Travel*）。
    
    - **常规做法的问题：** 普通的随机切分打乱了时间顺序 。
    - **核心概念 (Time Travel)：** 如果随机切分，你很可能把 **2023年** 的代码分到了训练集，把 **2020年** 的代码分到了测试集。
    - **后果：** 这就相当于模型拿着“未来的知识”去预测“过去的数据” 。因为开发者修复 Bug 的模式是会演进的，同一个 Commit 里修复多个相似漏洞的情况也很常见，随机切分会导致模型在训练时就见过了测试集里那个 Commit 的其他部分，从而泄露了信息 。
    - **正确做法：** 必须按*时间切分（Chronological Split）*，只能用过去的数据训练，预测未来的数据 。
    
    *2)Time Travel: Existing datasets also have the issue of time travel since they randomly separate functions into train, validation, and test sets(训练集、验证集、测试集）. Consequently, it is possible to train on future data and test on past data. It is also possible to have the fixed nonvulnerable function in the training set, and the older vulnerable function in the test set.(Page 5 Para1)*
    
    *However, training and testing with samples from the same commit is unrealistic and leaks information from the test time to the training time. In a realistic setting, the models are trained on the historical data to predict future samples.(Page 5 Para2 L7-Final)*
    
    **2）比例失真:** 强行构造 1:1 的正负样本，忽视了现实中漏洞极度稀缺（Base Rate Problem）。
    
    - **实验室环境 (The Lab)：** 为了方便模型训练，以前的研究者通常会构造一个比较平衡的数据集（比如有漏洞和没漏洞的样本比例接近，或者人为平衡过），让你感觉随便猜都有 50% 的胜算。
    - **真实环境 (Reality)：** 在真实软件开发中，漏洞是非常**稀缺**的（Rare） 。绝大多数代码（比如 99.9%）都是安全的。
    - **Base Rate Problem：** 指的就是这种“实验室里的高比例”和“现实中的极低比例”之间的巨大**不匹配 (mismatches)** 。在这种不匹配下训练出来的模型，会对现实世界里的低概率事件（漏洞）产生错误的判断倾向。
    
    *Accuracy: Many benchmarks report accuracy scores, but accuracy is not an appropriate metric for vulnerability detection, because of the **base rate problem** (vulnerabilities are rare in practice; most code is not vulnerable) and because of mismatches in class balance (the proportion of vulnerable samples in most research datasets does not match the ratio of vulnerable code in real life).(Page2 Limitation in existing evaluation metrics L4-)*
    
    **3）指标失效:** F1 Score 掩盖了高误报率的问题 。
    
    - ***F1 的定义*：** 它是查准率和查全率的调和平均数 。它把“漏报”（False Negative）和“误报”（False Positive）看作是同等重要的惩罚 。
    - **现实的痛点：** 现实中安全代码是**绝大多数 (overwhelming majority)**
        - 如果模型有 **1% 的误报率**。
        - 在 1000 行代码里（假设只有 1 个真漏洞），这 1% 的误报率会产生 **10 个假警报**。
        - 程序员要处理 10 个假警报才能找到 1 个真漏洞，这会导致严重的**警报疲劳 (Alert Fatigue)** 。
        
        *This dual expectation(平衡假阳性（false positives）和假阴性（false negatives） reflects the practical tradeoffs in software development: missed vulnerabilities can lead to security breaches, while too many false alarms can lead to alert fatigue, potentially causing real issues to be ignored. F1 and accuracy offer little insight into the tradeoff between false negatives and positives.(Page 5 Detection Error Tradeoffs L6-L11)*
        
    
    - **结论：** F1 Score 看不到这种不对称性 。一个 F1 分数很高的工具，如果误报太多，在实践中也是**没用的 (useless)** 。

*F1: While the F1 score is widely perceived to be a better metric for assessing classification performance on imbalanced datasets, we argue that it is not appropriate in reality either.The F1 score (the harmonic mean of precision and recall) reflects both false positives and false negatives by combining them into a single penalty. Yet, **for VD tools in practice, the overwhelming majority of code is not vulnerable**, so a critical challenge is preventing excessive false alarms.The F1 score fails to reflect this asymmetry, so tools with a high F1 score may be useless in practice.(Page 2)*

---

### **Approach（方法）**

### **1. 建立新数据集 PRIMEVUL**

**具体方法：**

**1）严格标注规则（Strict Labeling Criteria）**

作者先收集了 BigVul, CrossVul, CVEfixes 等一堆旧的“脏”数据集放在一起 ，再设计了两个过滤器，确保数据不是Noisy Labels:

① PRIMEVUL-ONEFUNC (针对单函数修改)

- 避免 “commit message + 靠调用链推断” 导致的误标。
- **新规则：** 只收录那些“仅仅修改了一个函数”的 Commit。只有函数本身能独立造成安全风险才被标为漏洞。
- **为什么这么做？** 如果一个 Commit 只动了一个函数，那么这个函数大概率就是漏洞所在，几乎没有“连带修改”或“重构”的干扰。这极大提高了准确率。

*PRIMEVUL-ONEFUNC: We notice that the previous labeling method has errors particularly when dealing with commits that modify multiple functions. Therefore, PRIMEVUL-ONEFUNC regards a function as vulnerable if it’s **the only** function changed by a security-related commit.(Page 5)*

② PRIMEVUL-NVDCHECK (针对 CVE 描述校验)

- **原理：** 利用权威的 **NVD（国家漏洞数据库）**。每个 CVE 漏洞都有详细的文字描述（比如“`login.c` 文件中的 `auth` 函数存在溢出”）。
- **新规则：** 拿代码里的函数名去跟 NVD 的描述做**文本匹配**。
    - 只有当 NVD 描述里**明确写出了这个函数的名字**，或者写出了文件名且该文件只改了一个函数时，才算数。
- **为什么这么做？** 这是用“专家知识”（CVE 描述）来验证“代码变更”，相当于请了安全专家来做自动审核。

*PRIMEVUL-NVDCHECK: Since human experts have analyzed the CVEs in the NVD database, the vulnerability description in each CVE entry is a reliable reference to label vulnerable functions. We develop PRIMEVUL-NVDCHECK as
the following. First, we link security-related commits to their CVE numbers and the vulnerability description in the NVD database. We label a function as vulnerable if it satisfies one of the two following criteria: (1) NVD description explicitly mentions its name, or (2) NVD description mentions its file name, and it is the only function changed by the security-related commit in that file.*

**2）**覆盖 **140 种 CWE（Common Weakness Enumeration，通用弱点枚举）**。

- CWE 是国际通用的漏洞分类标准。
- PrimeVul 数据集更全面、更接近真实软件安全场景。

**3）**漏洞数据量比现有最准确数据集 **大 16.7×**。

- 通过自动化 + 精准规则，获得比已有可靠数据集大 **16.7 倍** 的高质量漏洞数据。

### **2. 数据去重（Deduplication）与时间切分（Temporal Split）**

**（1）语义级去重（Semantic Deduplication）**

- 不只按 hash 匹配，而是按“语义”（semantic）判断是否重复。
- 避免训练集和测试集出现“同一份代码换个变量名”的情况。

**（2）按 commit 时间做切分**

- 训练（Train） → 开发验证（Dev） → 测试（Test）
- 完全基于时间排序，避免未来信息泄露。

### **3. 新评测指标：VD-S（Vulnerability Detection Score）**

- 在 **FPR ≤ 0.5%（False Positive Rate，假阳性率）** 条件下最小化 **FNR（False Negative Rate，假阴性率）**。
- 比传统 F1 更符合真实安全扫描需求（宁可 FP 多一点，也不能漏报漏洞）。

**旧方法 (F1)：** 找一个“误报”和“漏报”的平衡点。
**新方法 (VD-S)：** 我们不要平衡。我们的要求是：

1. **前提：** 你的“误报”必须非常非常少（`FPR 小于等于0.5%`）。
2. **目标：** 在满足前提1的工具里，谁能把“漏报”（`FNR`）降到最低，谁就是最好的。

这完美地体现了安全领域“**可以接受烦（FP），但绝不能瞎（FN）**”的核心思想。

### **4. Pair-wise Evaluation（成对评测）**

构造 “漏洞版本（Buggy） vs 修复版本（Patched）” 的代码对：

- 测试模型是否真正理解漏洞语义
- 不再依赖表层 token 模式（Pattern Matching）

---

## **Research Questions（研究问题，RQ）**

**RQ1：现有漏洞检测数据集质量到底如何？**

→ 作者系统性分析了 BigVul/Devign 的标签质量、重复率与数据泄露。

**RQ2：在更真实的数据集（PrimeVul）上，现有 Code LMs 表现如何？**

→ 评估 7B、13B、GPT-3.5、GPT-4 等模型。

**RQ3：更大模型或更强训练方法能否解决问题？**

→ 尝试微调、指令调优、对比训练等。

**RQ4：使用新指标和成对评测，模型是否能真正理解漏洞？**

→ 测试漏洞语义理解能力。

---

## **Results（主要结果）**

### **1. 当前模型在严格数据集上的表现接近随机**

- 7B SOTA 模型：
    - BigVul：**68.26% F1**
    - PRIMEVUL：**3.09% F1**
        
        说明原有评估体系严重高估模型能力。
        

### **2. GPT-3.5 / GPT-4 表现也大幅下降**

- 在严格的 PRIMEVUL + 新指标 VD-S 下，效果接近随机。

### **3. 先进训练手段（对比学习、pair-wise fine-tune 等）也无法显著提升性能**

### **4. PRIMEVUL 标签准确率 ≈ 人工审查级别，规模远大于同类数据集**